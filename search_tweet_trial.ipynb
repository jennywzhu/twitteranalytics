{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## pip install searchtweets\n",
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "premium_search_args = load_credentials(\".twitter_keys.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"Mueller Report\", \"toDate\": \"201904190000\", \"fromDate\": \"201904170000\"}\n"
     ]
    }
   ],
   "source": [
    "rule = gen_rule_payload('Mueller Report',\n",
    "                        from_date=\"2019-04-17\",\n",
    "                        to_date=\"2019-04-19\") # testing with a sandbox account\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultStream: \n",
      "\t{\n",
      "    \"username\": null,\n",
      "    \"endpoint\": \"https://api.twitter.com/1.1/tweets/search/fullarchive/BTG.json\",\n",
      "    \"rule_payload\": {\n",
      "        \"query\": \"Mueller Report\",\n",
      "        \"toDate\": \"201904190000\",\n",
      "        \"fromDate\": \"201904170000\"\n",
      "    },\n",
      "    \"tweetify\": true,\n",
      "    \"max_results\": 500\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rs = ResultStream(rule_payload=rule,\n",
    "                  #max_results=10,\n",
    "                  #max_pages=1,\n",
    "                  **premium_search_args)\n",
    "\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## makes 1 request every time you call this (limit 50 requests/month)\n",
    "tweets = list(rs.stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Mueller Report\" from 4-17-2019 to 4-19-2019\n",
    "\n",
    "import copy\n",
    "p_tweets = copy.deepcopy(tweets)\n",
    "\n",
    "file1 = open(\"mueller.csv\", \"w+\", encoding=\"utf-8\")\n",
    "headers1 = ['created_at, id, id_str, text, source, truncated, in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, user_id, user_screen_name, geo, coordinates, place, contributors, retweeted_id, is_quote_status, quote_count, reply_count, retweet_count, favorite_count, entities, favorited, retweeted, filter_level, lang, matching_rules']\n",
    "file1.write(\"{}\\n\".format(','.join(header for header in headers1))) \n",
    "\n",
    "file2 = open(\"mueller_users.csv\", \"w\", encoding=\"utf-8\") \n",
    "headers2 = ['id, id_str, name, screen_name, location, url, description, translator_type, protected, verified, followers_count, friends_count, listed_count, favourites_count, statuses_count, created_at, utc_offset, time_zone, geo_enabled, lang, contributors_enabled, is_translator, profile_background_color, profile_background_image_url, profile_background_image_url_https, profile_background_tile, profile_link_color, profile_sidebar_border_color, profile_sidebar_fill_color, profile_text_color, profile_use_background_image, profile_image_url, profile_image_url_https, profile_banner_url, default_profile, default_profile_image, following, follow_request_sent, notifications'] \n",
    "file2.write(\"{}\\n\".format(','.join(header for header in headers2))) \n",
    "\n",
    "file3 = open(\"mueller_retweets.csv\", \"w\", encoding=\"utf-8\") \n",
    "headers3 = ['created_at, id, id_str, text, source, truncated, in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, user, geo, coordinates, place, contributors, is_quote_status, extended_tweet, quote_count, reply_count, retweet_count, favorite_count, entities, favorited, retweeted, filter_level, lang'] \n",
    "file3.write(\"{}\\n\".format(','.join(header for header in headers3))) \n",
    "\n",
    "for i in range(len(p_tweets)): \n",
    "    params = list(p_tweets[i].values())\n",
    "    if(i in [22,38,44,45,51,57,62,77,88,144,170,182,187,210,237,239,248,270,274,277,314,334,362,424,425,430,476,494]):\n",
    "        continue\n",
    "#         t_params = params[:11] + params[12:] \n",
    "#         params = t_params\n",
    "    fields = params[:11]\n",
    "\n",
    "    user_id = params[11]['id'] \n",
    "    user_screen_name = params[11]['screen_name']\n",
    "    fields.extend([user_id,user_screen_name]) \n",
    "    user_fields = list(list(params[11].values()))\n",
    "    \n",
    "    fields += params[12:16] \n",
    "    if(params[16] == False):\n",
    "        fields.append(None)\n",
    "        retweet_fields = []*27\n",
    "    else:\n",
    "        fields.append(params[16]['id'])\n",
    "        retweet_fields = list(list(params[16].values()))\n",
    "    \n",
    "    fields += params[17:]\n",
    "    \n",
    "    file1.write(\"{}\\n\".format(','.join(str(field) for field in fields)))\n",
    "    file2.write(\"{}\\n\".format(','.join(str(u_field) for u_field in user_fields)))\n",
    "    file3.write(\"{}\\n\".format(','.join(str(r_field) for r_field in retweet_fields)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
